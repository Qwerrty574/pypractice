{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from  sklearn  import  preprocessing\n",
    "\n",
    "from random import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import neighbors # для knn классификации\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import copy\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "from random import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from random import *\n",
    "import math\n",
    "#from math import *\n",
    "##from pylab import *\n",
    "##import matplotlib.pyplot as plt\n",
    "##from matplotlib import cm\n",
    "##from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  sklearn  import  preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "import pickle  \n",
    "#from sklearn.externals import joblib\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from copy import deepcopy\n",
    "from random import uniform, randint\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#import seaborn as sns\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory='./' #папка с файлами\n",
    "       \n",
    "#files_name=os.listdir(directory) \n",
    "#files = [os.path.join(directory,f) for f in files_name]\n",
    "f = os.path.join(directory, 'pima-indians-diabetes.csv')\n",
    "              \n",
    "data=pd.read_csv(f, sep=',') #, , na_values=' ')\n",
    "#data.columns = ['A' + str(i) for i in range(1, 25)] +['Label']\n",
    "data.columns = ['A' + str(i) for i in range(1, 9)] + ['class']\n",
    "                 \n",
    "data.at[data['class']==2,'class']=0 # нет заболевания (редкие)\n",
    "data.at[data['class']==1,'class']=1  # \n",
    "\n",
    "#data=data.rename(columns={'Label':'class'})\n",
    "\n",
    "\n",
    "#data= pd.read_csv(f,sep=';',header=None,na_values=' ')\n",
    " \n",
    "X_first_format = data.drop(('class'), axis=1)  # Выбрасываем столбец 'class'.\n",
    "\n",
    "#data.at[data['class']=='NRB','class']=0 #отсутствие заболевания +1\n",
    "#data.at[data['class']=='RB','class']=1 # наличие -1\n",
    "\n",
    "\n",
    "\n",
    "# data_1_tr, data_1_te=train_test_split(data[data['class']==1] , test_size=0.1, random_state=rn_split)\n",
    "# data=pd.concat([data[data['class']==0], data_1_te], axis=0)\n",
    "\n",
    "X_first_format = data.drop(('class'), axis=1)  # Выбрасываем столбец 'class'.\n",
    "#imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#imp.fit(X_first_format)\n",
    "#train_X_first_format = imp.transform(X_first_format)\n",
    "        \n",
    "#min_max_scaler=preprocessing.MinMaxScaler()\n",
    "#X=min_max_scaler.fit_transform(train_X_first_format)\n",
    "                 \n",
    "                 #ВНИМАТЕЛЬНО!!!!!!!! \n",
    "y=data['class']\n",
    "#scaler=StandardScaler()\n",
    "#X = pd.DataFrame(scaler.fit_transform(X_first_format))\n",
    "scaler=MinMaxScaler()\n",
    "X=pd.DataFrame(scaler.fit_transform(X_first_format))\n",
    "XX=X_first_format # ИСПОЛЬЗУЕМ ПОТОМ ЭТО!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.039318\n",
       "1    0.025823\n",
       "2    0.025203\n",
       "3    0.025970\n",
       "4    0.018569\n",
       "5    0.013823\n",
       "6    0.020035\n",
       "7    0.038366\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    267\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts() # 0 -мажоритарный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " averTime= 0.03029129695892334\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "t1=time.time()\n",
    "clf=SVC()\n",
    "averTime=0\n",
    "max_acc=0\n",
    "N=500\n",
    "for i in range(N):\n",
    "    t1=time.time()    \n",
    "    rn_split=i\n",
    "    X_tr, X_te, y_tr, y_te=train_test_split(XX,y, test_size=0.2, random_state=rn_split)\n",
    "    \n",
    "    # НОРМИРОВКА!!!!\n",
    "    standard_scaler=preprocessing.StandardScaler()\n",
    "    X_tr = pd.DataFrame(standard_scaler.fit_transform(X_tr))\n",
    "          \n",
    "    X_te = pd.DataFrame(standard_scaler.transform(X_te)) \n",
    "    X_tr=X_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.astype('int64')\n",
    "    y_te=y_te.astype('int64')\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    pred=clf.predict(X_te)\n",
    "    t2=time.time()\n",
    "    deltaT=t2-t1  \n",
    "    averTime=averTime+deltaT    \n",
    "    current_acc=accuracy_score(y_te, pred)\n",
    "    if max_acc<current_acc:\n",
    "        max_acc=current_acc\n",
    "        i_acc=i\n",
    "# Standard\n",
    "# SVC() - default\n",
    "# i_acc= 4777  max_acc= 0.865\n",
    "\n",
    "#t2=time.time()\n",
    "#deltaT=t2-t1\n",
    "TimeSVM=averTime/N\n",
    "print(' averTime=', averTime/N)\n",
    "# Standard\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 1549  max_acc= 0.83\n",
    "\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 2989  max_acc= 0.795\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() \n",
    "# i_acc= 7  max_acc= 0.845\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " i_acc= 294  max_acc= 0.8506493506493507\n"
     ]
    }
   ],
   "source": [
    "print (' i_acc=', i_acc, ' max_acc=', max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " averTime= 0.0331944055557251\n"
     ]
    }
   ],
   "source": [
    "#OneClassSVM\n",
    "#t1=time.time()\n",
    "clf=OneClassSVM()\n",
    "averTime=0\n",
    "max_acc=0\n",
    "N=500\n",
    "for i in range(N):\n",
    "    t1=time.time()    \n",
    "    rn_split=i\n",
    "    X_tr, X_te, y_tr, y_te=train_test_split(XX,y, test_size=0.2, random_state=rn_split)\n",
    "    \n",
    "    # НОРМИРОВКА!!!!\n",
    "    standard_scaler=preprocessing.StandardScaler()\n",
    "    X_tr = pd.DataFrame(standard_scaler.fit_transform(X_tr))\n",
    "          \n",
    "    X_te = pd.DataFrame(standard_scaler.transform(X_te)) \n",
    "    X_tr=X_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.astype('int64')\n",
    "    y_te=y_te.astype('int64')\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    pred=clf.predict(X_te)\n",
    "    t2=time.time()\n",
    "    deltaT=t2-t1  \n",
    "    averTime=averTime+deltaT    \n",
    "    current_acc=accuracy_score(y_te, pred)\n",
    "    if max_acc<current_acc:\n",
    "        max_acc=current_acc\n",
    "        i_acc=i\n",
    "# MinMax\n",
    "# SVC() - default\n",
    "# i_acc= 4777  max_acc= 0.865\n",
    "\n",
    "#t2=time.time()\n",
    "#deltaT=t2-t1\n",
    "TimeOneClassSVM=averTime/N\n",
    "print(' averTime=', averTime/N)\n",
    "# MinMax\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 1549  max_acc= 0.83\n",
    "\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 2989  max_acc= 0.795\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() \n",
    "# i_acc= 7  max_acc= 0.845\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " averTime= 0.29291816759109496\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier\n",
    "#t1=time.time()\n",
    "clf=RandomForestClassifier()\n",
    "averTime=0\n",
    "max_acc=0\n",
    "N=500\n",
    "for i in range(N):\n",
    "    t1=time.time()    \n",
    "    rn_split=i\n",
    "    X_tr, X_te, y_tr, y_te=train_test_split(XX,y, test_size=0.2, random_state=rn_split)\n",
    "    \n",
    "    # НОРМИРОВКА!!!!\n",
    "    standard_scaler=preprocessing.StandardScaler()\n",
    "    X_tr = pd.DataFrame(standard_scaler.fit_transform(X_tr))\n",
    "          \n",
    "    X_te = pd.DataFrame(standard_scaler.transform(X_te)) \n",
    "    X_tr=X_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.astype('int64')\n",
    "    y_te=y_te.astype('int64')\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    pred=clf.predict(X_te)\n",
    "    t2=time.time()\n",
    "    deltaT=t2-t1  \n",
    "    averTime=averTime+deltaT    \n",
    "    current_acc=accuracy_score(y_te, pred)\n",
    "    if max_acc<current_acc:\n",
    "        max_acc=current_acc\n",
    "        i_acc=i\n",
    "# MinMax\n",
    "# SVC() - default\n",
    "# i_acc= 4777  max_acc= 0.865\n",
    "\n",
    "#t2=time.time()\n",
    "#deltaT=t2-t1\n",
    "TimeRF=averTime/N\n",
    "print(' averTime=', averTime/N)\n",
    "# MinMax\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 1549  max_acc= 0.83\n",
    "\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 2989  max_acc= 0.795\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() \n",
    "# i_acc= 7  max_acc= 0.845\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " averTime= 0.02517035150527954\n"
     ]
    }
   ],
   "source": [
    "#kNN\n",
    "#t1=time.time()\n",
    "clf=neighbors.KNeighborsClassifier() \n",
    "averTime=0\n",
    "max_acc=0\n",
    "N=500\n",
    "for i in range(N):\n",
    "    t1=time.time()    \n",
    "    rn_split=i\n",
    "    X_tr, X_te, y_tr, y_te=train_test_split(XX,y, test_size=0.2, random_state=rn_split)\n",
    "    \n",
    "    # НОРМИРОВКА!!!!\n",
    "    standard_scaler=preprocessing.StandardScaler()\n",
    "    X_tr = pd.DataFrame(standard_scaler.fit_transform(X_tr))\n",
    "          \n",
    "    X_te = pd.DataFrame(standard_scaler.transform(X_te)) \n",
    "    X_tr=X_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.reset_index(drop=True)\n",
    "    y_tr=y_tr.astype('int64')\n",
    "    y_te=y_te.astype('int64')\n",
    "    clf.fit(X_tr,y_tr)\n",
    "    pred=clf.predict(X_te)\n",
    "    t2=time.time()\n",
    "    deltaT=t2-t1  \n",
    "    averTime=averTime+deltaT   \n",
    "    current_acc=accuracy_score(y_te, pred)\n",
    "    if max_acc<current_acc:\n",
    "        max_acc=current_acc\n",
    "        i_acc=i\n",
    "# MinMax\n",
    "# SVC() - default\n",
    "# i_acc= 4777  max_acc= 0.865\n",
    "\n",
    "#t2=time.time()\n",
    "#deltaT=t2-t1\n",
    "TimekNN=averTime/N\n",
    "print(' averTime=', averTime/N)\n",
    "# MinMax\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 1549  max_acc= 0.83\n",
    "\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() - gamma=1\n",
    "# i_acc= 2989  max_acc= 0.795\n",
    "\n",
    "\n",
    "# StandardScaler\n",
    "# SVC() \n",
    "# i_acc= 7  max_acc= 0.845\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TimeSVM= 0.03029129695892334  TimeOneClassSVM= 0.0331944055557251  TimekNN= 0.02517035150527954  TimeRF= 0.29291816759109496\n",
      " TimeSVM/TimekNN= 1.203451487460144\n",
      " TimeOneClassSVM/TimekNN= 1.318789908387354\n",
      " TimeSVM/TimeRF= 0.10341214820519118\n",
      " TimeOneClassSVM/TimeRF= 0.11332313672692199\n",
      " TimeRF/TimekNN= 11.637428564700603\n"
     ]
    }
   ],
   "source": [
    "print(' TimeSVM=', TimeSVM, ' TimeOneClassSVM=', TimeOneClassSVM,' TimekNN=',TimekNN, ' TimeRF=',TimeRF )\n",
    "\n",
    "print(' TimeSVM/TimekNN=', TimeSVM/TimekNN)\n",
    "print(' TimeOneClassSVM/TimekNN=', TimeOneClassSVM/TimekNN)\n",
    "\n",
    "\n",
    "print(' TimeSVM/TimeRF=', TimeSVM/TimeRF)\n",
    "print(' TimeOneClassSVM/TimeRF=', TimeOneClassSVM/TimeRF)\n",
    "\n",
    "print(' TimeRF/TimekNN=', TimeRF/TimekNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deltaT= 0.028057575225830078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "t1=time.time()\n",
    "clf=SVC()\n",
    "clf.fit(X_tr,y_tr)\n",
    "t2=time.time()\n",
    "deltaT=t2-t1\n",
    "print(' deltaT=', deltaT)\n",
    "\n",
    "pred=clf.predict(X_te)\n",
    "accuracy_score(y_te, pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deltaT= 0.28436994552612305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=time.time()\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_tr,y_tr)\n",
    "t2=time.time()\n",
    "deltaT=t2-t1\n",
    "print(' deltaT=', deltaT)\n",
    "pred=clf.predict(X_te)\n",
    "accuracy_score(y_te, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deltaT= 0.007707118988037109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7727272727272727"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=time.time()\n",
    "clf=neighbors.KNeighborsClassifier() \n",
    "clf.fit(X_tr,y_tr)\n",
    "t2=time.time()\n",
    "deltaT=t2-t1\n",
    "print(' deltaT=', deltaT)\n",
    "pred=clf.predict(X_te)\n",
    "accuracy_score(y_te, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deltaT= 0.025359630584716797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1038961038961039"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "t1=time.time()\n",
    "clf=OneClassSVM()\n",
    "clf.fit(X_tr,y_tr)\n",
    "t2=time.time()\n",
    "deltaT=t2-t1\n",
    "print(' deltaT=', deltaT)\n",
    "\n",
    "pred=clf.predict(X_te)\n",
    "accuracy_score(y_te, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}